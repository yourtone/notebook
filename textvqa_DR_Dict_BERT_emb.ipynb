{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/home/lyt/code/concept_vqa'\n",
    "data_folder = '{}/dataTVQA'.format(root_folder)\n",
    "ori_emb_size = 768\n",
    "new_emb_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab_emb(emb_file, emb_size):\n",
    "    with open(emb_file) as f:\n",
    "        raw = f.read().splitlines()\n",
    "    word_vec = [l.split(' ', 1) for l in raw]\n",
    "    vocab, vecs_txt = zip(*word_vec)\n",
    "    vecs = np.fromstring(' '.join(vecs_txt), dtype='float32', sep=' ')\n",
    "    vecs = vecs.reshape(-1, emb_size)\n",
    "    return vocab, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab_emb(emb_file, vocab, emb):\n",
    "    emb = emb.tolist()\n",
    "    emb = [['{:f}'.format(xx) for xx in x] for x in emb]\n",
    "    vocab = [[v] for v in vocab]\n",
    "    y = list(zip(vocab,emb))\n",
    "    z = [' '.join(yy[0]+yy[1]) for yy in y]\n",
    "    with open(emb_file, 'w') as f:\n",
    "        f.write('\\n'.join(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load] /home/lyt/code/concept_vqa/dataTVQA/word-embedding/bert.768d.txt ...\n",
      "[Info] Dict emb shape: (400000, 768)\n"
     ]
    }
   ],
   "source": [
    "emb_file = '{}/word-embedding/bert.{}d.txt'.format(data_folder, ori_emb_size)\n",
    "print('[Load] {} ...'.format(emb_file))\n",
    "vocab, dic_emb = load_vocab_emb(emb_file, ori_emb_size)\n",
    "print('[Info] Dict emb shape: {}'.format(dic_emb.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcafile = '{}/word-embedding/pca_dict.bert.{}-{}.pkl'.format(data_folder, ori_emb_size, new_emb_size)\n",
    "if os.path.exists(pcafile):\n",
    "    with open(pcafile, 'rb') as f:\n",
    "        pca=pickle.load(f)\n",
    "else:\n",
    "    pca = PCA(n_components=new_emb_size)\n",
    "    pca.fit(dic_emb)\n",
    "    with open(pcafile, 'wb') as f:\n",
    "        pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] New dict emb shape: (400000, 300)\n"
     ]
    }
   ],
   "source": [
    "new_dic_emb = pca.transform(dic_emb)\n",
    "print('[Info] New dict emb shape: {}'.format(new_dic_emb.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Write] /home/lyt/code/concept_vqa/dataTVQA/word-embedding/bert.300d.txt ...\n"
     ]
    }
   ],
   "source": [
    "emb_file = '{}/word-embedding/bert.PCA.{}d.txt'.format(data_folder, new_dic_emb.shape[1])\n",
    "print('[Write] {} ...'.format(emb_file))\n",
    "write_vocab_emb(emb_file, vocab, new_dic_emb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
