{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/home/lyt/code/vqa-concept'\n",
    "data_folder = '{}/dataTVQA'.format(root_folder)\n",
    "fea_folder = '{}/image-feature/bottomup'.format(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embeddings(embedding_names):\n",
    "    names = embedding_names.split('+')\n",
    "    vocabs = []\n",
    "    vecs = []\n",
    "    for name in names:\n",
    "        vocab, vec = load_embeddings(name)\n",
    "        vocabs.append(vocab)\n",
    "        vecs.append(vec)\n",
    "\n",
    "    final_vocab = set(vocabs[0])\n",
    "    for vocab in vocabs[1:]:\n",
    "        final_vocab &= set(vocab)\n",
    "    final_vocab = list(final_vocab)\n",
    "\n",
    "    final_vec = []\n",
    "    for vocab, vec in zip(vocabs, vecs):\n",
    "        w2i = dict(zip(vocab, range(len(vocab))))\n",
    "        inds = np.array([w2i[w] for w in final_vocab])\n",
    "        final_vec.append(vec[inds])\n",
    "    final_vec = np.hstack(final_vec)\n",
    "\n",
    "    return dict(zip(final_vocab, final_vec))\n",
    "\n",
    "def load_embeddings(name):\n",
    "    emb_path = '{}/word-embedding/{}'.format(data_folder, name)\n",
    "    #logger.debug('[Load] ' + emb_path)\n",
    "    with open(emb_path) as f:\n",
    "        word_vec_txt = [l.rstrip().split(' ', 1) for l in f.readlines()]\n",
    "    vocab, vecs_txt = zip(*word_vec_txt)\n",
    "    # infer vector dimention\n",
    "    vec_size = len(vecs_txt[0].split())\n",
    "    # fromstring faster than loadtxt\n",
    "    vecs = np.fromstring(' '.join(vecs_txt), dtype='float32', sep=' ')\n",
    "    vecs = vecs.reshape(-1, vec_size)\n",
    "    return vocab, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDINGS = 'bert.PCA.300d.txt'\n",
    "word_vec = merge_embeddings(WORD_EMBEDDINGS)\n",
    "aword = next(iter(word_vec))\n",
    "emb_size = len(word_vec[aword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/objects_vocab.txt'.format(data_folder)) as f:\n",
    "    objects_vocab = f.read().splitlines()\n",
    "objects_vocab = ['__no_objects__'] + objects_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_embedding(class_name, word_vec, emb_size):\n",
    "    synonyms = class_name.split(',')\n",
    "    act_num = []\n",
    "    act_ratio = []\n",
    "    for label in synonyms:\n",
    "        words = label.split()\n",
    "        act = sum([1 for word in words if word in word_vec])\n",
    "        act_num.append(act)\n",
    "        act_ratio.append(act / len(words))\n",
    "    act_idx = max(range(len(act_num)), key=lambda x: act_ratio[x])\n",
    "    vec = np.zeros((emb_size,), dtype='float32')\n",
    "    pretrained_avail = act_num[act_idx] > 0\n",
    "    if pretrained_avail:\n",
    "        for word in synonyms[act_idx].split():\n",
    "            if word in word_vec:\n",
    "                vec += word_vec[word]\n",
    "        vec /= act_num[act_idx]\n",
    "    return pretrained_avail, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = '{}/{}_100_class-prob.npy'.format(fea_folder, 'train')\n",
    "valfile = '{}/{}_100_class-prob.npy'.format(fea_folder, 'val')\n",
    "testfile = '{}/{}_100_class-prob.npy'.format(fea_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.load(trainfile)\n",
    "valX = np.load(valfile)\n",
    "testX = np.load(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] class embedding filling count: 1596/1601\n",
      "(21953, 100, 1601)\n",
      "(3166, 100, 1601)\n",
      "(3289, 100, 1601)\n",
      "(1601, 300)\n"
     ]
    }
   ],
   "source": [
    "obj_emb = np.zeros((len(objects_vocab), emb_size), dtype='float32')\n",
    "fill_cnt = 0\n",
    "for i, line in enumerate(objects_vocab):\n",
    "    avail, vec = get_class_embedding(line, word_vec, emb_size)\n",
    "    if avail:\n",
    "        obj_emb[i] = vec\n",
    "        fill_cnt += 1\n",
    "print('[debug] class embedding filling count: {}/{}'.format(fill_cnt, len(objects_vocab)))\n",
    "print(trainX.shape)\n",
    "print(valX.shape)\n",
    "print(testX.shape)\n",
    "print(obj_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX = np.dot(trainX,obj_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaX = np.dot(valX,obj_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teX = np.dot(testX,obj_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21953, 100, 300)\n",
      "(3166, 100, 300)\n",
      "(3289, 100, 300)\n"
     ]
    }
   ],
   "source": [
    "print(trX.shape)\n",
    "print(vaX.shape)\n",
    "print(teX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = '{}/{}_100_class-emb.npy'.format(fea_folder, 'train')\n",
    "valfile = '{}/{}_100_class-emb.npy'.format(fea_folder, 'val')\n",
    "testfile = '{}/{}_100_class-emb.npy'.format(fea_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(trainfile,trX)\n",
    "np.save(valfile,vaX)\n",
    "np.save(testfile,teX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
